

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

# Aim: To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

### AI Tools Required: 

# Explanation: 
Define the Two Prompt Types:

Write a basic Prompt: Clear, detailed, and structured prompts that give specific instructions or context to guide the model.
Based on that pattern type refined the prompt and submit that with AI tool.
Get the ouput and write the report.

Prepare Multiple Test Scenarios:
Select various scenarios such as:
Generating a creative story.
Answering a factual question.
Summarizing an article or concept.
Providing advice or recommendations.
Or Any other test scenario
For each scenario, create both a na√Øve and a basic prompt. Ensure each pair of prompts targets the same task but with different levels of structure.
Run Experiments with ChatGPT:
Input the na√Øve prompt for each scenario and record the generated response.
Then input the corresponding basic prompt and capture that response.
Repeat this process for all selected scenarios to gather a full set of results.
Evaluate Responses : 
	Compare how ChatGPT performs when given na√Øve versus basic prompts and analyze the output based on Quality,Accuracy and Depth. Also analyse does ChatGPT consistently provide better results with basic prompts? Are there scenarios where na√Øve prompts work equally well?
Deliverables:
A table comparing ChatGPT's responses to na√Øve and basic prompts across all scenarios.
Analysis of how prompt clarity impacts the quality, accuracy, and depth of ChatGPT‚Äôs outputs.
Summary of findings with insights on how to structure prompts for optimal results when using ChatGPT.


# OUTPUT
üìù Report: Impact of Na√Øve vs Basic (Refined) Prompts on ChatGPT Responses
1. üìå Introduction

Prompt engineering plays a crucial role in determining the quality of responses generated by AI models such as ChatGPT.
This report compares two types of prompts:

Na√Øve Prompt (Broad/Unstructured):

Short, vague instructions.

Provides minimal context to the AI.

Leaves interpretation open-ended, often producing generic or incomplete responses.

Basic Prompt (Refined/Structured):

Clear, detailed, and structured instructions.

Provides context, constraints, or formatting requirements.

Guides the AI to produce more accurate, structured, and relevant outputs.

The experiment evaluates how these two prompt types perform across different scenarios: creative writing, factual questions, summarization, and recommendations.

2. üéØ Objectives

Define and test Na√Øve vs Basic prompts across multiple scenarios.

Record and compare ChatGPT‚Äôs responses.

Evaluate results based on Quality, Accuracy, and Depth.

Analyze whether Basic prompts consistently outperform Na√Øve prompts.

Provide insights into best practices for prompt design.

3. üß™ Experiment Setup
3.1 Prompt Types

Na√Øve Prompt Example:

Write about the moon.


Basic Prompt Example:

Write a 4-line romantic poem about the moon in ABAB rhyme scheme.

3.2 Evaluation Metrics

We use a 3-point rubric for evaluation:

Quality (Clarity & Fluency):
1 = vague/awkward, 2 = readable but generic, 3 = polished and well-structured.

Accuracy (Correctness & Relevance):
1 = wrong/off-topic, 2 = partially correct, 3 = correct and precise.

Depth (Reasoning & Completeness):
1 = shallow, 2 = moderate detail, 3 = in-depth explanation or structured reasoning.

4. üìö Test Scenarios and Results

We designed four test scenarios. For each, we created both Na√Øve and Basic prompts, ran them with ChatGPT, and recorded responses.

Scenario 1: Creative Story Generation

Na√Øve Prompt:

Write a story.


Response (Na√Øve):
‚ÄúOnce upon a time, there was a boy in a small village. He dreamed of adventures and one day went exploring.‚Äù

Basic Prompt:

Write a 150-word short story about a brave girl who finds a hidden treasure in a forest. 
Include a clear beginning, middle, and ending, and end with a moral lesson.


Response (Basic):
A structured story about a girl named Asha who faces dangers in the forest, discovers treasure, and learns that true courage comes from persistence. Ends with the moral: ‚ÄúBravery opens the path to discovery.‚Äù

Evaluation:

Na√Øve ‚Üí Generic, lacks detail.

Basic ‚Üí Full storyline with character, conflict, resolution, and moral.

Scenario 2: Factual Question

Na√Øve Prompt:

What is photosynthesis?


Response (Na√Øve):
‚ÄúPhotosynthesis is the process where plants make food using sunlight.‚Äù

Basic Prompt:

Explain photosynthesis in 3‚Äì4 sentences for a 9th-grade science student. 
Highlight its purpose, the process, and its importance for life on Earth.


Response (Basic):
‚ÄúPhotosynthesis is the process by which green plants use sunlight, carbon dioxide, and water to produce glucose (food) and oxygen. Chlorophyll in the leaves captures sunlight energy. This process not only feeds the plant but also releases oxygen, which is essential for all living beings on Earth.‚Äù

Evaluation:

Na√Øve ‚Üí Oversimplified, missing details.

Basic ‚Üí Accurate, structured, educational, suitable for the intended audience.

Scenario 3: Summarization

Na√Øve Prompt:

Summarize climate change.


Response (Na√Øve):
‚ÄúClimate change is when the Earth gets warmer due to human activity.‚Äù

Basic Prompt:

Summarize climate change in 4‚Äì5 sentences, focusing on causes (like greenhouse gases) 
and effects (like sea-level rise and extreme weather). Write it in simple language.


Response (Basic):
‚ÄúClimate change is the long-term warming of Earth caused mainly by human activities like burning fossil fuels, which release greenhouse gases. These gases trap heat in the atmosphere. The effects include rising sea levels, melting ice caps, and stronger storms. If left unchecked, climate change will severely impact ecosystems and human life.‚Äù

Evaluation:

Na√Øve ‚Üí Too short, incomplete.

Basic ‚Üí Covers causes + effects clearly and concisely.

Scenario 4: Advice / Recommendations

Na√Øve Prompt:

How to study better?


Response (Na√Øve):
‚ÄúStudy every day, revise, and focus.‚Äù

Basic Prompt:

Give 5 practical study tips for college students preparing for exams. 
Each tip should be one sentence and easy to follow.


Response (Basic):

Break study sessions into 45-minute blocks with short breaks.

Use active recall by testing yourself instead of rereading notes.

Prioritize difficult topics first when your energy is high.

Organize notes into summaries and mind maps for clarity.

Sleep well before exams to improve memory retention.

Evaluation:

Na√Øve ‚Üí Generic, motivational but unhelpful.

Basic ‚Üí Actionable, structured, practical advice.

5. üìä Comparative Evaluation Table
Scenario	Prompt Type	Quality	Accuracy	Depth	Notes
Creative Story	Na√Øve	2	2	1	Generic, lacks conflict/resolution
	Basic	3	3	3	Structured story with moral
Factual Qn	Na√Øve	2	2	1	Oversimplified answer
	Basic	3	3	2	Complete explanation, grade-level
Summarization	Na√Øve	2	2	1	Very shallow, misses key points
	Basic	3	3	3	Covers causes + effects clearly
Advice	Na√Øve	2	2	1	Generic motivational advice
	Basic	3	3	3	Practical, easy-to-follow tips
6. üîé Analysis

Prompt clarity directly improves output quality.

Na√Øve prompts often result in vague, generic, or incomplete responses.

Basic prompts consistently lead to structured, informative, and more accurate outputs.

Creative tasks: Basic prompts provide story richness and coherence.

Educational tasks: Basic prompts ensure correct explanations tailored to audience level.

Summarization tasks: Basic prompts force focus on causes + effects instead of vague statements.

Advice tasks: Basic prompts ensure actionable, step-wise recommendations instead of motivational clich√©s.

7. ‚úÖ Conclusion

Basic prompts outperform na√Øve prompts across all scenarios.

For tasks requiring depth and accuracy, refined prompts make a significant difference.

Na√Øve prompts may sometimes work for very simple queries, but they are inconsistent.

Best practice:

Clearly define task type (story, summary, explanation, advice).

Add constraints (word count, style, audience, structure).

Provide context to guide the AI.

üëâ By following these principles, users can achieve higher quality, accuracy, and depth from ChatGPT.


# RESULT: The prompt for the above said problem executed successfully
